{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.decomposition import PCA\n\ndef carregar_dados(url, nomes_colunas):\n    \"\"\"Carrega os dados a partir de uma URL e retorna um DataFrame.\"\"\"\n    data = pd.read_csv(url, names=nomes_colunas, header=0)\n    return data\n\ndef pre_processamento(X, y):\n    \"\"\"Realiza o pré-processamento dos dados.\"\"\"\n    # Imputação dos valores faltantes\n    imputer = SimpleImputer(strategy='most_frequent')\n    y = imputer.fit_transform(y.values.reshape(-1, 1))\n    y = pd.Series(y.flatten())\n\n    # Identificação dos tipos de atributos\n    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n    categorical_features = X.select_dtypes(include=['object']).columns\n\n    # Construção dos pipelines de transformação\n    numeric_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='median')),\n        ('scaler', StandardScaler())\n    ])\n\n    categorical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\n    # Aplicação das transformações nos dados\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_features),\n            ('cat', categorical_transformer, categorical_features)\n        ],\n        sparse_threshold=0\n    )\n    return preprocessor, y\n\ndef avaliar_modelo(modelo, X, y, pre_processor, nome_modelo):\n    \"\"\"Avalia um modelo usando validação cruzada e exibe métricas de desempenho.\"\"\"\n    pipeline = Pipeline(steps=[\n        ('pre_processor', pre_processor),\n        ('classifier', modelo)\n    ])\n    skf = StratifiedKFold(n_splits=8, shuffle=True, random_state=42)\n    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n    accuracy = accuracy_score(y, y_pred)\n    f1 = f1_score(y, y_pred, average='weighted')\n    \n    print(f\"Modelo: {nome_modelo}\")\n    print(\"Acurácia:\", accuracy)\n    print(\"F1-Score:\", f1)\n\n    # Matriz de confusão\n    cm = confusion_matrix(y, y_pred)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {nome_modelo}')\n    plt.show()\n\n# URL dos dados e nomes das colunas\nurl = \"https://raw.githubusercontent.com/tmfilho/akcdata/master/data/akc-data-latest.csv\"\nnomes_colunas = ['raça', 'descrição', 'temperamento', 'popularidade', 'altura_mínima', 'altura_máxima',\n                 'peso_mínimo', 'peso_máximo', 'expectativa_vida_mínima', 'expectativa_vida_máxima', 'grupo',\n                 'frequência_escovação_valor', 'frequência_escovação_categoria', 'queda_valor', 'queda_categoria',\n                 'nível_energia_valor', 'nível_energia_categoria', 'facilidade_treinamento_valor', 'facilidade_treinamento_categoria',\n                 'comportamento_valor', 'categoria_comportamento']\n\n# Carregar os dados\ndata = carregar_dados(url, nomes_colunas)\n\n# Separarando os atributos de entrada e alvo\nX = data.drop(columns=['categoria_comportamento'])\ny = data['categoria_comportamento']\n\n# Pré-processamento dos dados\npre_processor, y = pre_processamento(X, y)\n\n# Modelos a serem avaliados\nmodelos = {\n    'Árvore de Decisão': DecisionTreeClassifier(random_state=42),\n    'Naive Bayes': GaussianNB(),\n    'MLP': MLPClassifier(random_state=42)\n}\n\n# Avaliar modelos\nfor nome, modelo in modelos.items():\n    avaliar_modelo(modelo, X, y, pre_processor, nome)\n\n# Modelos com PCA\nfor nome, modelo in modelos.items():\n    pipeline_pca = Pipeline(steps=[\n        ('preprocessor', pre_processor),\n        ('pca', PCA(n_components=0.95)),  # Manter 95% da variância explicada\n        ('classifier', modelo)\n    ])\n    avaliar_modelo(modelo, X, y, pre_processor, f'{nome} com PCA')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\"\"\" \n    Todas importações necessárias para o pré-processamento dos dados,\n    o teste de Algoritmos e avaliação dos resultados\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.decomposition import PCA",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\"\"\" Agora a explicação de cada função utilizada para responder a questão \"\"\"\n\n\"\"\"\n    Recebe como parâmetros a URL do conjunto de dados e os nomes das colunas.\n    Lê o arquivo CSV utilizando o pandas e retorna um DataFrame com os dados.\n\"\"\"\n\ndef carregar_dados(url, nomes_colunas):\n    \"\"\"Carrega os dados a partir de uma URL e retorna um DataFrame.\"\"\"\n    data = pd.read_csv(url, names=nomes_colunas, header=0)\n    return data\n\n\n\"\"\"\n    No pré-processamento e recebido os Dataframes de entrada e alvo (X, y)\n    Imputa valores ausentes em y utilizando o SimpleImputer com estratégia most_frequent.\n    Identifica os tipos de atributos em X: numéricos (int64, float64) e categóricos (object).\n    Cria pipelines de transformação para cada tipo de atributo:\n    Numéricos:\n    Imputa valores ausentes com estratégia median usando o SimpleImputer.\n    Normaliza os dados com o StandardScaler.\n    Categóricos:\n    Imputa valores ausentes com estratégia most_frequent usando o SimpleImputer.\n    Codifica os dados usando o OneHotEncoder e estratégia handle_unknown='ignore'.\n    Combina os pipelines de transformação em um único ColumnTransformer.\n    Retorna o ColumnTransformer e o DataFrame y pré-processado\n\"\"\"\n\ndef pre_processamento(X, y):\n    \"\"\"Realiza o pré-processamento dos dados.\"\"\"\n    # Imputação dos valores faltantes\n    imputer = SimpleImputer(strategy='most_frequent')\n    y = imputer.fit_transform(y.values.reshape(-1, 1))\n    y = pd.Series(y.flatten())\n\n    # Identificação dos tipos de atributos\n    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n    categorical_features = X.select_dtypes(include=['object']).columns\n\n    # Construção dos pipelines de transformação\n    numeric_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='median')),\n        ('scaler', StandardScaler())\n    ])\n\n    categorical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\n    # Aplicação das transformações nos dados\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_features),\n            ('cat', categorical_transformer, categorical_features)\n        ],\n        sparse_threshold=0\n    )\n    return preprocessor, y\n\n\n\"\"\"\n    Recebe como parâmetros o modelo a ser avaliado (modelo), os DataFrames de entrada (X) e alvo (y), o pré-processador (pre_processor) e o nome do modelo.\n    Cria um pipeline que combina o pré-processador e o modelo.\n    Realiza validação cruzada estratificada com 8 divisões (K=8) usando o StratifiedKFold.\n    Prediz as classes para cada fold usando o cross_val_predict.\n    Calcula a acurácia e o F1-Score utilizando as funções accuracy_score e f1_score, respectivamente.\n    Exibe as métricas de desempenho para o modelo.\n    Gera uma matriz de confusão usando o confusion_matrix e a visualiza com seaborn.\n\"\"\"\n\ndef avaliar_modelo(modelo, X, y, pre_processor, nome_modelo):\n    \"\"\"Avalia um modelo usando validação cruzada e exibe métricas de desempenho.\"\"\"\n    pipeline = Pipeline(steps=[\n        ('pre_processor', pre_processor),\n        ('classifier', modelo)\n    ])\n    skf = StratifiedKFold(n_splits=8, shuffle=True, random_state=42)\n    y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n    accuracy = accuracy_score(y, y_pred)\n    f1 = f1_score(y, y_pred, average='weighted')\n    \n    print(f\"Modelo: {nome_modelo}\")\n    print(\"Acurácia:\", accuracy)\n    print(\"F1-Score:\", f1)\n\n    # Matriz de confusão\n    cm = confusion_matrix(y, y_pred)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {nome_modelo}')\n    plt.show()\n\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "\"\"\"\n    E por último esse trecho do código é onde é chamada as funções\n    explicadas anteriormentes, e passado os dados corretamentes\n    para que obtenha os resultados.\n\"\"\"\n\n# URL dos dados e nomes das colunas\nurl = \"https://raw.githubusercontent.com/tmfilho/akcdata/master/data/akc-data-latest.csv\"\nnomes_colunas = ['raça', 'descrição', 'temperamento', 'popularidade', 'altura_mínima', 'altura_máxima',\n                 'peso_mínimo', 'peso_máximo', 'expectativa_vida_mínima', 'expectativa_vida_máxima', 'grupo',\n                 'frequência_escovação_valor', 'frequência_escovação_categoria', 'queda_valor', 'queda_categoria',\n                 'nível_energia_valor', 'nível_energia_categoria', 'facilidade_treinamento_valor', 'facilidade_treinamento_categoria',\n                 'comportamento_valor', 'categoria_comportamento']\n\n\n# Carregar os dados do csv\ndata = carregar_dados(url, nomes_colunas)\n\n# Separarando os atributos de entrada e alvo\nX = data.drop(columns=['categoria_comportamento'])\ny = data['categoria_comportamento']\n\n# Pré-processamento dos dados\npre_processor, y = pre_processamento(X, y)\n\n# Modelos a serem avaliados\nmodelos = {\n    'Árvore de Decisão': DecisionTreeClassifier(random_state=42),\n    'Naive Bayes': GaussianNB(),\n    'MLP': MLPClassifier(random_state=42)\n}\n\n# Avaliando modelos\nfor nome, modelo in modelos.items():\n    avaliar_modelo(modelo, X, y, pre_processor, nome)\n\n# Modelos com PCA\nfor nome, modelo in modelos.items():\n    pipeline_pca = Pipeline(steps=[\n        ('preprocessor', pre_processor),\n        ('pca', PCA(n_components=0.95)),  # Manter 95% da variância explicada\n        ('classifier', modelo)\n    ])\n    avaliar_modelo(modelo, X, y, pre_processor, f'{nome} com PCA')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}